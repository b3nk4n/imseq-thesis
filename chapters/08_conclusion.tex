% !TeX root = ../main.tex

\chapter{Conclusion} \label{chapter:conclusion}

We presented existing unsupervised deep learning approaches for future frame prediction in videos and incorporated their mentioned insights to build a neural network model that combines the its strengths. Our finally proposed network architecture utilizes the recurrent decoder-encoder framework using ConvLSTM cells that are able to preserve the spatio-temporal correlations of the data. Further, the extensive use of batch normalization and the scheduled sampling training strategy enables our model to outperform many existing approaches in at least synthetic or simple videos, even though our network contains a lower model complexity and is trained for fewer iterations. An identified key driver to obtain accurate prediction results has been the choice of an appropriate loss function that considers human perception. However, the best composition of different objective functions strongly depends on the underlying data. We further evaluated our network quantitatively and qualitatively on three datasets of different complexity in several scenarios and investigated the models behavior regarding hyperparameter changes. The best performing model in each case was then compared to results from related works. Additionally, we presented a high-level framework for TensorFlow projects that enables to use advanced features out-of-the-box and radically reduces boilerplate code.

\section{Discussion}

After applying batch normalization and the scheduled sampling learning strategy, we were honestly surprised that our model was able to outperform related models by such a large margin. Nevertheless, we belief that is still space to improve the proposed architecture, the chosen hyperparameter configuration and particularly the data preprocessing. Regarding the latter, only simple rescaling of the data has been performed to be roughly zero mean, but dedicated the scaling of the values completely to batch normalization layers and the entire network.

We could also figure out that the choice of the appropriate loss function has a huge impact regarding the generated future frame predictions, if not even the most tremendous effects. However, as the evaluation in chapter \ref{chapter:evaluation} clearly shows, there is no perfect solution for this purpose. But it must be emphasized that the detailed properties of the used image or video data have to be analyzed in detail, in order to be able to achieve good results. Having said that, the fine-tuning of neural networks in context of image processing tasks remains to be very difficult even with a good loss function at hand. This can be attributed to the discrepancy between the mathematical and perceptual similarity of two images. Also the use of perceptual motivated metrics presented in Section \ref{sec:img_metrics} is not always very helpful, because an increase in one metric can lead to a decline in others. It is easy to get lost when multiple metrics are used.

Finally, we assume that our model could be currently trained more effectively using a different deep learning framework than TensorFlow, at least at the time of this writing. This can be argued with the fact that the current batch normalization layer in this framework currently depends on some operations where no GPU kernel is implemented yet. Such a bottleneck might be the root cause why the training process of our model is so slow that it requires up to four days to train the network for only \num{100000} steps. But this will certainly change in one of its next releases.


\section{Future Work}

There are at least the following five proposals for future work:

Firstly, the proposed network model should be examined and fine-tuned in more detail. We strongly belief that this architecture is able to obtain even better results after performing a more extensive hyperparameter search, training it for many more iterations or when using a larger dataset like Sports-1M. Unfortunately, this is beyond the timeframe of this thesis, that is why we had to perform some evaluations on networks which still had more potential in case of more training iterations.

Secondly, because the application of the scheduled sampling learning strategy for recurrent networks has improved our results in such an extent, it would be worthwhile experimenting with new variants of this approach. For instance, the recurrent network could dynamically grow in the course of the training process. Thereby, it could start to predict a single frame only until the validation loss reaches a specified threshold. Afterwards, the decoder RNN can be extended at runtime to predict more and more future frames per training iteration. As a result, such a network should be able to predict longer sequences with a higher stability regarding the quality of generated frames. 

Thirdly, since the GAN approach described in Section \ref{sec:related_gan} yields such promising results, one has to image what might be possible when we plug our proposed model into this adversarial framework. Despite the fact that they use the probably simplest generator network we can think of, our model as a replacement for their generator network would explicitly take advantage of the spatio-temporal properties of the data. Especially without the need that the model would have to learn these correlations from scratch. As a consequence, the additional adversarial network would introduce an additional objective function in feature space, whose benefits have already been mentioned in the end of section \ref{sec:impl-components}.

Next, a trained network instance of our model can be examined to serve as a pre-training for supervised learning tasks like human action recognition, which can be very helpful according to \parencite[p. 20]{deep_arch_ai}. Similar efforts have already been taken in \parencite{unsup_learn_lstm} with positive results. In detail, we should be able to detach the encoder components of our trained model, including its ability to generate a useful feature space representation given a sequence of frames, and plug it into a different network architecture specialized for classification. Unfortunately, performing such experiments with labeled video data is beyond the scope of this thesis.

Lastly, the proposed network architecture itself can be further extended to cope with different unsupervised tasks. To name just one, the recurrent components can be updated to bidirectional RNNs in order to solve tasks like slow motion video generation or video compression more effectively.